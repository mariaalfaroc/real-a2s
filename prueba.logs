nohup: ignoring input
Device cuda
Supervised training experiment
Namespace(batch_size=16, dataset='Primus', epochs=300, multirest=False, num_iters=1, num_samples=1000, patience=20)
Data used Primus
Iter 0
/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:443: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/Convolution.cpp:647.)
  self.padding, self.dilation, self.groups)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
CRNN                                     [1, 128, 1628]            --
├─CNN: 1-1                               [1, 8, 57, 128]           --
│    └─Sequential: 2-1                   [1, 8, 57, 128]           --
│    │    └─Conv2d: 3-1                  [1, 8, 229, 256]          160
│    │    └─BatchNorm2d: 3-2             [1, 8, 229, 256]          16
│    │    └─LeakyReLU: 3-3               [1, 8, 229, 256]          --
│    │    └─MaxPool2d: 3-4               [1, 8, 114, 128]          --
│    │    └─Conv2d: 3-5                  [1, 8, 114, 128]          2,560
│    │    └─BatchNorm2d: 3-6             [1, 8, 114, 128]          16
│    │    └─LeakyReLU: 3-7               [1, 8, 114, 128]          --
│    │    └─MaxPool2d: 3-8               [1, 8, 57, 128]           --
├─RNN: 1-2                               [1, 128, 1628]            --
│    └─LSTM: 2-2                         [1, 128, 512]             3,039,232
│    └─Dropout: 2-3                      [1, 128, 512]             --
│    └─Linear: 2-4                       [1, 128, 1628]            835,164
==========================================================================================
Total params: 3,877,148
Trainable params: 3,877,148
Non-trainable params: 0
Total mult-adds (M): 436.59
==========================================================================================
Input size (MB): 0.23
Forward/backward pass size (MB): 11.56
Params size (MB): 15.51
Estimated Total Size (MB): 27.31
==========================================================================================
Epoch 1/300
loss: 5.4211 - val_ser: 100.00 - 44s
SER improved from inf to 100.00. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 2/300
loss: 5.1941 - val_ser: 100.00 - 4s
Epoch 3/300
loss: 5.3215 - val_ser: 100.00 - 4s
Epoch 4/300
loss: 4.8411 - val_ser: 97.55 - 4s
SER improved from 100.00 to 97.55. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 5/300
loss: 5.0573 - val_ser: 97.35 - 4s
SER improved from 97.55 to 97.35. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 6/300
loss: 4.8595 - val_ser: 97.16 - 4s
SER improved from 97.35 to 97.16. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 7/300
loss: 4.4332 - val_ser: 96.24 - 4s
SER improved from 97.16 to 96.24. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 8/300
loss: 4.2217 - val_ser: 95.93 - 4s
SER improved from 96.24 to 95.93. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 9/300
loss: 3.7383 - val_ser: 96.26 - 4s
Epoch 10/300
loss: 3.4276 - val_ser: 95.70 - 4s
SER improved from 95.93 to 95.70. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 11/300
loss: 3.4147 - val_ser: 95.43 - 4s
SER improved from 95.70 to 95.43. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 12/300
loss: 3.3322 - val_ser: 95.35 - 4s
SER improved from 95.43 to 95.35. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 13/300
loss: 3.1793 - val_ser: 95.35 - 4s
Epoch 14/300
loss: 2.9214 - val_ser: 95.31 - 4s
SER improved from 95.35 to 95.31. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 15/300
loss: 2.7241 - val_ser: 94.90 - 4s
SER improved from 95.31 to 94.90. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 16/300
loss: 2.4627 - val_ser: 93.05 - 4s
SER improved from 94.90 to 93.05. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 17/300
loss: 2.2988 - val_ser: 89.67 - 3s
SER improved from 93.05 to 89.67. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 18/300
loss: 2.2769 - val_ser: 87.62 - 4s
SER improved from 89.67 to 87.62. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 19/300
loss: 2.1266 - val_ser: 80.68 - 4s
SER improved from 87.62 to 80.68. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 20/300
loss: 1.8958 - val_ser: 73.03 - 4s
SER improved from 80.68 to 73.03. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 21/300
loss: 1.8865 - val_ser: 65.62 - 4s
SER improved from 73.03 to 65.62. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 22/300
loss: 1.7672 - val_ser: 60.95 - 3s
SER improved from 65.62 to 60.95. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 23/300
loss: 1.6541 - val_ser: 59.43 - 4s
SER improved from 60.95 to 59.43. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 24/300
loss: 1.5575 - val_ser: 52.95 - 3s
SER improved from 59.43 to 52.95. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 25/300
loss: 1.9204 - val_ser: 51.76 - 3s
SER improved from 52.95 to 51.76. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 26/300
loss: 1.6373 - val_ser: 47.36 - 4s
SER improved from 51.76 to 47.36. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 27/300
loss: 1.5819 - val_ser: 46.29 - 4s
SER improved from 47.36 to 46.29. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 28/300
loss: 1.3015 - val_ser: 46.04 - 4s
SER improved from 46.29 to 46.04. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 29/300
loss: 1.3360 - val_ser: 44.46 - 4s
SER improved from 46.04 to 44.46. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 30/300
loss: 1.4741 - val_ser: 43.18 - 4s
SER improved from 44.46 to 43.18. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 31/300
loss: 1.2305 - val_ser: 42.67 - 4s
SER improved from 43.18 to 42.67. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 32/300
loss: 1.1237 - val_ser: 43.30 - 5s
Epoch 33/300
loss: 1.2020 - val_ser: 41.49 - 4s
SER improved from 42.67 to 41.49. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 34/300
loss: 1.1178 - val_ser: 41.88 - 4s
Epoch 35/300
loss: 1.1775 - val_ser: 40.61 - 4s
SER improved from 41.49 to 40.61. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 36/300
loss: 1.2511 - val_ser: 40.30 - 4s
SER improved from 40.61 to 40.30. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 37/300
loss: 1.2834 - val_ser: 42.21 - 4s
Epoch 38/300
loss: 1.2070 - val_ser: 41.02 - 4s
Epoch 39/300
loss: 1.0397 - val_ser: 40.67 - 4s
Epoch 40/300
loss: 0.9965 - val_ser: 40.30 - 4s
Epoch 41/300
loss: 1.0310 - val_ser: 40.63 - 4s
Epoch 42/300
loss: 1.0530 - val_ser: 40.18 - 4s
SER improved from 40.30 to 40.18. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 43/300
loss: 1.1865 - val_ser: 39.85 - 4s
SER improved from 40.18 to 39.85. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 44/300
loss: 1.0830 - val_ser: 39.58 - 4s
SER improved from 39.85 to 39.58. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 45/300
loss: 0.9869 - val_ser: 39.33 - 4s
SER improved from 39.58 to 39.33. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 46/300
loss: 1.0260 - val_ser: 39.05 - 4s
SER improved from 39.33 to 39.05. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 47/300
loss: 0.9640 - val_ser: 39.46 - 4s
Epoch 48/300
loss: 0.9008 - val_ser: 39.15 - 4s
Epoch 49/300
loss: 0.9562 - val_ser: 38.72 - 5s
SER improved from 39.05 to 38.72. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 50/300
loss: 0.9050 - val_ser: 37.75 - 4s
SER improved from 38.72 to 37.75. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 51/300
loss: 0.8543 - val_ser: 37.54 - 4s
SER improved from 37.75 to 37.54. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 52/300
loss: 0.9016 - val_ser: 36.95 - 4s
SER improved from 37.54 to 36.95. Saving model's weights to DATASETS/Primus/experiments/1000/Iter0.pt
Epoch 53/300
loss: 0.9093 - val_ser: 39.52 - 4s
Epoch 54/300
loss: 0.9767 - val_ser: 38.45 - 4s
Epoch 55/300
loss: 0.8947 - val_ser: 38.00 - 4s
Epoch 56/300
loss: 0.9360 - val_ser: 38.02 - 4s
Epoch 57/300
loss: 0.9046 - val_ser: 37.93 - 4s
Epoch 58/300
loss: 0.9718 - val_ser: 38.92 - 4s
Epoch 59/300
loss: 0.8550 - val_ser: 38.86 - 4s
Epoch 60/300
loss: 0.8743 - val_ser: 37.44 - 4s
Epoch 61/300
loss: 0.8218 - val_ser: 38.02 - 4s
Epoch 62/300
loss: 0.7544 - val_ser: 37.56 - 4s
Epoch 63/300
loss: 0.7088 - val_ser: 37.91 - 4s
Epoch 64/300
loss: 0.7077 - val_ser: 38.59 - 4s
Epoch 65/300
loss: 0.6544 - val_ser: 38.35 - 4s
Epoch 66/300
loss: 0.6768 - val_ser: 37.65 - 4s
Epoch 67/300
loss: 0.7645 - val_ser: 37.85 - 4s
Epoch 68/300
loss: 0.7863 - val_ser: 37.73 - 3s
Epoch 69/300
loss: 0.6971 - val_ser: 36.99 - 4s
Epoch 70/300
loss: 0.7773 - val_ser: 38.28 - 5s
Epoch 71/300
loss: 0.5893 - val_ser: 38.26 - 4s
Epoch 72/300
loss: 0.5794 - val_ser: 37.87 - 4s
Stopped by early stopping on epoch: 72
Evaluating best validation model over test data
SER (%): 40.06 - From 200 samples
Prediction - ['clef-G2', 'keySignature-FM', 'timeSignature-C', 'rest-eighth', 'note-C5_eighth', 'note-E5_eighth', 'note-E5_eighth', 'rest-eighth', 'note-E5_eighth', 'note-F5_eighth', 'note-G5_eighth', 'note-D5_eighth', 'note-D5_eighth', 'rest-eighth', 'note-B4_eighth', 'note-C5_eighth', 'note-D5_eighth', 'note-E5_sixteenth', 'note-F5_sixteenth', 'barline', 'note-G#4_quarter.', 'note-A4_eighth', 'note-A4_quarter.', 'note-G4_eighth', 'note-G4_quarter', 'note-G4_quarter']
Ground truth - ['clef-C1', 'keySignature-BbM', 'timeSignature-C', 'rest-eighth', 'note-C5_eighth', 'note-Eb5_eighth', 'note-Eb5_eighth', 'rest-eighth', 'note-Eb5_eighth', 'note-F5_eighth', 'note-G5_eighth', 'barline', 'note-D5_eighth', 'note-D5_eighth', 'rest-eighth', 'note-B4_eighth', 'note-C5_eighth', 'note-D5_eighth', 'note-Eb5_sixteenth', 'note-F5_sixteenth', 'barline', 'note-Ab4_quarter.', 'note-A4_eighth', 'note-A4_quarter.', 'note-G4_eighth', 'barline', 'note-G4_quarter', 'note-G4_quarter', 'rest-eighth']
Saving experiment's logs to DATASETS/Primus/experiments/1000/Iter0.csv
